import os
import cv2
from ultralytics import YOLO
import numpy as np

# ---------------- è¨­å®š ---------------- #
MODEL_PATH = "yolov8s.pt"      # æ¨¡å‹
INPUT_TYPE = "video"           # "image" æˆ– "video"
IMAGE_FOLDER = "images/"       # å¦‚æœæ˜¯åœ–ç‰‡æ¨¡å¼ â†’ è³‡æ–™å¤¾è·¯å¾‘
VIDEO_PATH = "videos/984.mp4"  # å¦‚æœæ˜¯å½±ç‰‡æ¨¡å¼ â†’ å½±ç‰‡è·¯å¾‘
OUTPUT_FOLDER = "output/"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# è¨­å®šç•«é¢æ»¿å“¡çš„é¢ç©æ¯”ä¾‹ (50%)
CAPACITY_THRESHOLD = 0.5

# ---------------- åˆå§‹åŒ–æ¨¡å‹ ---------------- #
model = YOLO(MODEL_PATH)

# è¨ˆç®—æ‰€æœ‰æ¡†çš„è¯é›†é¢ç©
def calculate_union_area(boxes, height, width):
    union_mask = np.zeros((height, width), dtype=np.uint8)
    for box in boxes:
        x1, y1, x2, y2 = map(int, box)
        union_mask[y1:y2, x1:x2] = 1
    return np.sum(union_mask)

# æ¨™è¨˜çµæœ
def display_result(frame, results):
    boxes = results[0].boxes.xyxy
    height, width, _ = frame.shape

    # è¨ˆç®—ç¸½ç‰©é«”è¯é›†é¢ç©
    union_area = calculate_union_area(boxes, height, width)
    frame_area = width * height
    area_ratio = union_area / frame_area

    # æ¡†æ¡†é¡è‰²
    box_color = (0, 255, 0) if area_ratio < CAPACITY_THRESHOLD else (0, 0, 255)

    # ç¹ªè£½æ¡†æ¡†
    for box in boxes:
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)

    # é¡¯ç¤ºç¸½é¢ç©æ¯”ä¾‹
    text = f"Area ratio: {area_ratio:.2f} {'(FULL!)' if area_ratio >= CAPACITY_THRESHOLD else ''}"
    cv2.putText(frame, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    return frame

# ---------------- åœ–ç‰‡æ¨¡å¼ ---------------- #
def process_images():
    print("ğŸ“· è™•ç†åœ–ç‰‡ä¸­...")
    for img_name in os.listdir(IMAGE_FOLDER):
        if img_name.lower().endswith((".jpg", ".jpeg", ".png")):
            img_path = os.path.join(IMAGE_FOLDER, img_name)
            image = cv2.imread(img_path)

            # YOLO åµæ¸¬
            results = model(image)
            image = display_result(image, results)

            # å„²å­˜çµæœ
            save_path = os.path.join(OUTPUT_FOLDER, img_name)
            cv2.imwrite(save_path, image)
            print(f"âœ… å„²å­˜åµæ¸¬çµæœåˆ° {save_path}")
    print("ğŸ‰ åœ–ç‰‡è™•ç†å®Œæˆï¼")

# ---------------- å½±ç‰‡æ¨¡å¼ ---------------- #
# ---------------- å½±ç‰‡æ¨¡å¼ ---------------- #
def process_video(video_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡ï¼š{video_path}")
        return

    # å½±ç‰‡è³‡è¨Š
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    # å–å¾—åŸå§‹æª”åï¼ˆä¸å«å‰¯æª”åï¼‰
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    output_path = os.path.join(OUTPUT_FOLDER, f"{base_name}_analyzed.mp4")

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame)
        frame = display_result(frame, results)
        out.write(frame)

        # å³æ™‚é¡¯ç¤ºï¼ˆå¯æŒ‰ q é›¢é–‹ï¼‰
        cv2.imshow("Analyzing Video", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

        frame_count += 1
        if frame_count % 30 == 0:
            print(f"ğŸ“¹ å·²è™•ç† {frame_count} å¹€...")

    cap.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"ğŸ‰ å½±ç‰‡è™•ç†å®Œæˆï¼Œè¼¸å‡ºåˆ° {output_path}")


# ---------------- ä¸»ç¨‹å¼ ---------------- #
if __name__ == "__main__":
    if INPUT_TYPE == "image":
        process_images()
    elif INPUT_TYPE == "video":
        process_video(VIDEO_PATH)
    else:
        print("âŒ INPUT_TYPE å¿…é ˆæ˜¯ 'image' æˆ– 'video'")
